#!/usr/bin/env python3
"""
Integration test for simplified Vietnamese RAG (2-stage: Retrieve + Generate).

Tests that Gemma 3 12B can answer Vietnamese questions directly from retrieved chunks
without needing structured extraction.

This validates the hypothesis: We don't need Stage 2 (extraction) - just retrieve
chunks and let Gemma 3 answer the question.
"""

import asyncio
import httpx
import pytest
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openai import OpenAIProvider


# Real chunk from hop_dong_mua_ban_2022.pdf containing equipment table
REAL_CHUNK_WITH_EQUIPMENT = """
### **Phá»¥c lá»¥c I DANH Má»¤C HÃ€NG HÃ“A**

| (KÃ¨m theo Há»£p Ä‘á»“ng sá»‘ /2022/HÄMB ngÃ y 06/01/2022) |

| TT | DANH Má»¤C HÃ€NG HÃ“A | QUY CÃCH (mÃ£ sá»‘, kÃ½ hiá»‡u) | XUáº¤T Xá»¨ | ÄVT   | SL | ÄÆ N GIÃ (VNÄ) | THÃ€NH TIá»€N (VNÄ) |
|----|-------------------|---------------------------|---------|-------|----|--------------:|------------------:|
| 1  | ÄÃ¨n Ä‘iá»‡n tá»«       | Ğ“ĞœĞ˜-46Ğ‘                   | Nga     | CÃ¡i   | 1  | 353.066.000   | 353.066.000       |
| 2  | ÄÃ¨n Ä‘iá»u cháº¿      | Ğ“Ğ¢Ğš1 1000/25              | Nga     | CÃ¡i   | 2  | 65.000.000    | 130.000.000       |
| 3  | Bá»™ chia           | Ğ˜Ğ—ĞĞ47                    | Nga     | Bá»™    | 8  | 120.000.000   | 960.000.000       |
| 4  | Bá»™ khuáº¿ch Ä‘áº¡i     | Ğ£Ğœ-100                    | Nga     | Bá»™    | 1  | 2.346.682.000 | 2.346.682.000     |
| 5  | Cáº£m biáº¿n          | AVM58-N                   | Nga     | CÃ¡i   | 1  | 28.851.000    | 28.851.000        |
| 6  | Cháº¥n tá»«           | Ğ˜Ğ—ĞĞ09                    | Nga     | CÃ¡i   | 7  | 75.000.000    | 525.000.000       |
| 7  | Cháº¥n tá»­           | Ğ˜Ğ—ĞĞ22                    | Nga     | CÃ¡i   | 11 | 60.000.000    | 660.000.000       |
| 8  | Cháº¥n tá»­           | Ğ˜Ğ—ĞĞ22Ğœ                   | Nga     | CÃ¡i   | 4  | 56.000.000    | 224.000.000       |

*Báº±ng chá»¯: MÆ°á»i má»™t tá»·, tÃ¡m trÄƒm báº£y mÆ°Æ¡i tÃ¡m triá»‡u, má»™t trÄƒm ba mÆ°Æ¡i lÄƒm nghÃ¬n tÃ¡m trÄƒm ba mÆ°Æ¡i má»‘t Ä‘á»“ng.*
"""


@pytest.mark.asyncio
async def test_gemma3_direct_answer_from_chunks():
    """
    Test that Gemma 3 12B can answer 'Thiáº¿t bá»‹ nÃ o Ä‘áº¯t nháº¥t?' directly from chunks.

    This validates we can skip extraction and go straight to generation.
    """

    print("\n" + "=" * 80)
    print("TEST: Simplified 2-Stage RAG (Retrieve â†’ Generate)")
    print("=" * 80)
    print("\nQuestion: Thiáº¿t bá»‹ nÃ o Ä‘áº¯t nháº¥t?")
    print("Expected Answer: Bá»™ khuáº¿ch Ä‘áº¡i at 2,346,682,000 VND\n")

    # Setup Gemma 3 12B model
    http_client = httpx.AsyncClient(timeout=120.0)

    model = OpenAIChatModel(
        model_name='/models/gemma-3-12b-it',
        provider=OpenAIProvider(
            base_url='http://localhost:8080/v1',
            api_key='dummy',
            http_client=http_client
        )
    )

    # Create a simple agent for Vietnamese Q&A
    agent = Agent(
        model,
        system_prompt="""Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn vá» há»£p Ä‘á»“ng tiáº¿ng Viá»‡t.

Tráº£ lá»i cÃ¢u há»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p trong tÃ i liá»‡u.
Chá»‰ sá»­ dá»¥ng thÃ´ng tin cÃ³ trong tÃ i liá»‡u, khÃ´ng bá»‹a Ä‘áº·t.
Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n vÃ  chÃ­nh xÃ¡c."""
    )

    # Simulate retrieved chunks (Stage 1 result)
    user_prompt = f"""Dá»±a trÃªn thÃ´ng tin trong tÃ i liá»‡u sau:

{REAL_CHUNK_WITH_EQUIPMENT}

CÃ¢u há»i: Thiáº¿t bá»‹ nÃ o Ä‘áº¯t nháº¥t?"""

    print("ğŸ”„ Generating answer with Gemma 3 12B...")

    try:
        result = await agent.run(user_prompt)
        answer = result.output

        print(f"\nâœ… Generated Answer:")
        print(f"   {answer}\n")

        # Validate answer
        answer_lower = answer.lower()

        assert "khuáº¿ch Ä‘áº¡i" in answer_lower, "Answer should mention 'khuáº¿ch Ä‘áº¡i'"

        # Check if price is mentioned (various formats)
        has_price = any([
            "2.346.682.000" in answer,
            "2,346,682,000" in answer,
            "2346682000" in answer,
            "2.3 tá»·" in answer_lower,
            "hai tá»· ba trÄƒm" in answer_lower
        ])

        assert has_price, "Answer should mention the price"

        print("âœ… VALIDATION PASSED:")
        print("   - Correctly identified 'Bá»™ khuáº¿ch Ä‘áº¡i'")
        print("   - Mentioned the price")
        print("\n" + "=" * 80)
        print("ğŸ¯ CONCLUSION: Gemma 3 12B can answer directly from chunks!")
        print("   â†’ Stage 2 (extraction) is NOT needed for Q&A")
        print("=" * 80)

        return True

    except AssertionError as e:
        print(f"\nâŒ VALIDATION FAILED: {e}")
        print("   Answer did not contain expected information")
        return False

    except Exception as e:
        print(f"\nâŒ TEST FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        await http_client.aclose()


@pytest.mark.asyncio
async def test_gemma3_list_all_equipment():
    """Test that Gemma 3 can list all equipment when asked."""

    print("\n" + "=" * 80)
    print("TEST: List all equipment (no extraction needed)")
    print("=" * 80)

    http_client = httpx.AsyncClient(timeout=120.0)

    model = OpenAIChatModel(
        model_name='/models/gemma-3-12b-it',
        provider=OpenAIProvider(
            base_url='http://localhost:8080/v1',
            api_key='dummy',
            http_client=http_client
        )
    )

    agent = Agent(
        model,
        system_prompt="""Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn vá» há»£p Ä‘á»“ng tiáº¿ng Viá»‡t.
Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, liá»‡t kÃª Ä‘áº§y Ä‘á»§ theo yÃªu cáº§u."""
    )

    user_prompt = f"""Dá»±a trÃªn thÃ´ng tin trong tÃ i liá»‡u sau:

{REAL_CHUNK_WITH_EQUIPMENT}

CÃ¢u há»i: Liá»‡t kÃª táº¥t cáº£ thiáº¿t bá»‹ vÃ  giÃ¡ cá»§a chÃºng."""

    print("ğŸ”„ Asking Gemma 3 to list all equipment...")

    try:
        result = await agent.run(user_prompt)
        answer = result.output

        print(f"\nâœ… Generated Answer:\n")
        print(answer)
        print()

        # Check if key equipment is mentioned
        answer_lower = answer.lower()
        mentioned_equipment = 0

        equipment_to_check = [
            "Ä‘Ã¨n Ä‘iá»‡n tá»«",
            "bá»™ chia",
            "khuáº¿ch Ä‘áº¡i",
            "cáº£m biáº¿n"
        ]

        for equipment in equipment_to_check:
            if equipment in answer_lower:
                mentioned_equipment += 1
                print(f"   âœ“ Found: {equipment}")

        print(f"\n   Total: {mentioned_equipment}/{len(equipment_to_check)} equipment items found")

        assert mentioned_equipment >= 3, "Should mention at least 3 equipment items"

        print("\nâœ… VALIDATION PASSED: Can list equipment without extraction")

        return True

    except Exception as e:
        print(f"\nâŒ TEST FAILED: {e}")
        return False

    finally:
        await http_client.aclose()


if __name__ == "__main__":
    """Run tests standalone."""

    print("\nğŸš€ SIMPLIFIED VIETNAMESE RAG TESTS")
    print("Testing hypothesis: We can skip extraction and answer directly\n")

    async def run_all_tests():
        test1 = await test_gemma3_direct_answer_from_chunks()
        test2 = await test_gemma3_list_all_equipment()

        print("\n" + "=" * 80)
        print("TEST SUMMARY")
        print("=" * 80)
        print(f"1. Direct Answer Test:  {'âœ… PASS' if test1 else 'âŒ FAIL'}")
        print(f"2. List Equipment Test: {'âœ… PASS' if test2 else 'âŒ FAIL'}")

        if test1 and test2:
            print("\nğŸ‰ ALL TESTS PASSED")
            print("\nğŸ“‹ RECOMMENDATION:")
            print("   Remove Stage 2 (extraction) from vietnamese_agent.py")
            print("   Use simplified 2-stage: Retrieve â†’ Generate")
        else:
            print("\nâš ï¸  SOME TESTS FAILED")
            print("   Extraction may still be needed")

        print("=" * 80)

    asyncio.run(run_all_tests())

#!/usr/bin/env python3
"""
Test Morphik Agent with vLLM Gemma 3 12B for tool calling.

This tests whether Gemma 3 12B can:
1. Use retrieve_chunks tool to get Vietnamese contract data
2. Optionally use execute_code tool for comparison
3. Generate Vietnamese answers

PydanticAI is disabled - using standard LiteLLM-based MorphikAgent.
"""

import asyncio
import httpx


async def test_morphik_agent_vietnamese_query():
    """
    Test Morphik Agent with Vietnamese query: 'Thi·∫øt b·ªã n√†o ƒë·∫Øt nh·∫•t?'

    Expected behavior:
    1. Agent calls retrieve_chunks tool
    2. Agent analyzes data (might use execute_code)
    3. Agent generates Vietnamese answer
    """

    print("\n" + "=" * 80)
    print("MORPHIK AGENT TEST - vLLM Gemma 3 12B Tool Calling")
    print("=" * 80)
    print("\nQuestion: Thi·∫øt b·ªã n√†o ƒë·∫Øt nh·∫•t?")
    print("Expected: B·ªô khu·∫øch ƒë·∫°i at 2,346,682,000 VND\n")

    print("üîÑ Sending query to /agent endpoint...")
    print("   Using: vLLM Gemma 3 12B (LiteLLM + MorphikAgent)")
    print("   PydanticAI: DISABLED\n")

    async with httpx.AsyncClient(timeout=300.0) as client:
        try:
            response = await client.post(
                'http://localhost:8000/agent',
                json={
                    "query": "Thi·∫øt b·ªã n√†o ƒë·∫Øt nh·∫•t?",
                    "end_user_id": "test-user"
                }
            )
            response.raise_for_status()
            data = response.json()

            print("=" * 80)
            print("RESPONSE RECEIVED")
            print("=" * 80)

            # Extract tool history
            tool_history = data.get('tool_history', [])
            print(f"\nüìã Tools Called: {len(tool_history)}")

            if tool_history:
                print("\nTool Call History:")
                for i, tool_call in enumerate(tool_history, 1):
                    tool_name = tool_call.get('tool_name', 'unknown')
                    print(f"   {i}. {tool_name}")

                    # Check if retrieve_chunks was called
                    if tool_name == 'retrieve_chunks':
                        print("      ‚úÖ Successfully called retrieve_chunks")

                    # Check if execute_code was called
                    if tool_name == 'execute_code':
                        print("      ‚úÖ Used execute_code for computation")
                        code = tool_call.get('input', {}).get('code', '')
                        if code:
                            print(f"      Code snippet (first 200 chars):")
                            print(f"      {code[:200]}")
            else:
                print("   ‚ö†Ô∏è  NO TOOLS CALLED")
                print("   This means Gemma 3 12B did not use function calling")
                print("   The model may have answered directly without retrieval")

            # Extract sources (retrieved chunks)
            sources = data.get('sources', [])
            print(f"\nüìÑ Sources Retrieved: {len(sources)}")

            if sources:
                print("\nSample sources:")
                for i, source in enumerate(sources[:2], 1):
                    doc_name = source.get('documentName', 'unknown')
                    score = source.get('score', 0.0)
                    content_preview = source.get('content', '')[:100]
                    print(f"   {i}. {doc_name} (score: {score:.3f})")
                    print(f"      {content_preview}...")

            # Extract answer
            answer = data.get('response', '')
            print(f"\nüí¨ Generated Answer:")
            print(f"   {answer}\n")

            # Validate answer
            answer_lower = answer.lower()

            validations = []

            # Check if mentions "khu·∫øch ƒë·∫°i"
            if "khu·∫øch ƒë·∫°i" in answer_lower:
                validations.append("‚úÖ Mentions 'B·ªô khu·∫øch ƒë·∫°i'")
            else:
                validations.append("‚ùå Does NOT mention 'B·ªô khu·∫øch ƒë·∫°i'")

            # Check if mentions price
            has_price = any([
                "2.346.682.000" in answer,
                "2,346,682,000" in answer,
                "2346682000" in answer,
                "2.3 t·ª∑" in answer_lower,
                "hai t·ª∑ ba trƒÉm" in answer_lower
            ])

            if has_price:
                validations.append("‚úÖ Mentions correct price")
            else:
                validations.append("‚ö†Ô∏è  Price not clearly mentioned")

            print("=" * 80)
            print("VALIDATION RESULTS")
            print("=" * 80)
            for validation in validations:
                print(f"   {validation}")

            print("\n" + "=" * 80)
            print("TOOL CALLING ASSESSMENT")
            print("=" * 80)

            if len(tool_history) == 0:
                print("‚ùå FAIL - Gemma 3 12B did NOT use tool calling")
                print("\nThis means:")
                print("  ‚Ä¢ Model answered directly without using retrieve_chunks")
                print("  ‚Ä¢ vLLM function calling may not work with Gemma 3 12B")
                print("  ‚Ä¢ Consider using Qwen3:32b with Ollama instead")

            elif 'retrieve_chunks' in [t.get('tool_name') for t in tool_history]:
                print("‚úÖ SUCCESS - Gemma 3 12B used tool calling correctly!")
                print("\nThe model:")
                print(f"  ‚Ä¢ Called {len(tool_history)} tool(s)")
                print("  ‚Ä¢ Retrieved data using retrieve_chunks")

                if 'execute_code' in [t.get('tool_name') for t in tool_history]:
                    print("  ‚Ä¢ Used execute_code for computation (BONUS!)")

                if "khu·∫øch ƒë·∫°i" in answer_lower and has_price:
                    print("  ‚Ä¢ Generated correct Vietnamese answer ‚úÖ")
                else:
                    print("  ‚Ä¢ Answer may be incomplete ‚ö†Ô∏è")
            else:
                print("‚ö†Ô∏è  PARTIAL - Called tools but not retrieve_chunks")
                print(f"   Tools called: {[t.get('tool_name') for t in tool_history]}")

            print("=" * 80)

            return len(tool_history) > 0

        except httpx.HTTPStatusError as e:
            print(f"\n‚ùå HTTP ERROR: {e}")
            print(f"   Status: {e.response.status_code}")
            print(f"   Response: {e.response.text[:500]}")
            return False

        except httpx.TimeoutException:
            print("\n‚ùå TIMEOUT: Agent took too long (>5 minutes)")
            print("   Possible issues:")
            print("   ‚Ä¢ vLLM is slow with Gemma 3 12B")
            print("   ‚Ä¢ Model is stuck in a loop")
            print("   ‚Ä¢ Tool execution is failing")
            return False

        except Exception as e:
            print(f"\n‚ùå ERROR: {e}")
            import traceback
            traceback.print_exc()
            return False


async def main():
    print("\nüöÄ TESTING MORPHIK AGENT WITH vLLM")
    print("Configuration:")
    print("  ‚Ä¢ Model: Gemma 3 12B IT")
    print("  ‚Ä¢ Backend: vLLM (OpenAI-compatible API)")
    print("  ‚Ä¢ Agent: MorphikAgent (LiteLLM)")
    print("  ‚Ä¢ PydanticAI: DISABLED")
    print()

    # Wait for morphik to be ready
    print("‚è≥ Waiting for morphik container to be ready...")
    await asyncio.sleep(10)

    success = await test_morphik_agent_vietnamese_query()

    print("\n" + "=" * 80)
    print("FINAL RESULT")
    print("=" * 80)

    if success:
        print("‚úÖ GEMMA 3 12B CAN USE TOOL CALLING WITH vLLM")
        print("\nRecommendation:")
        print("  ‚Ä¢ Keep vLLM Gemma 3 12B as agent model")
        print("  ‚Ä¢ Morphik Agent with tool calling works!")
        print("  ‚Ä¢ PydanticAI extraction not needed")
    else:
        print("‚ùå GEMMA 3 12B CANNOT USE TOOL CALLING RELIABLY")
        print("\nRecommendation:")
        print("  ‚Ä¢ Switch back to Ollama Qwen3:32b for agent")
        print("  ‚Ä¢ Use vLLM Gemma 3 only for Vietnamese generation")
        print("  ‚Ä¢ Tool calling requires better model support")

    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())
